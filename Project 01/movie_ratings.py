import sys
import pandas as pd
import numpy as np
#
# Here, we are reading movie_ratings.csv, which was a randomly generated by another program create_movie_ratings.py. We'll split this into
# train and test data sets. Since, we do not know how the actual data will look like, we used "?" for null entries, for the highest
# generality, and also for being close to the instruction YouTube video (https://www.youtube.com/playlist?list=PLuKhJYywjDe96T2L0-zXFU5Up2jqXlWI9).
# Our goal is to assume minimum advantage, and tackle the complexity in the program.
#
url = "https://raw.githubusercontent.com/forhadakbar/data612summer2020/master/Project%2001/movie_ratings.csv"
movie_ratings_df = pd.read_csv(url, index_col = 0)
#
rows, columns = movie_ratings_df.shape
#
print()
print("Given data set: movie_ratings_df")
print(movie_ratings_df)
#
# Here, we are reading movie_ratings.csv, which was a randomly generated by another program create_movie_ratings.py. It's a 16 x 7 data frame,
# populated by True and False values, at 25/75 ratio. Elements from movie_ratings_df will populate only the True-cells of movie_test_df,
# including "?" (as was in the instructions video).
#
url_test = "https://raw.githubusercontent.com/forhadakbar/data612summer2020/master/Project%2001/movie_test_df.csv"
movie_test_df = pd.read_csv(url_test, index_col = 0) # from github
#
print()
print("Starter data set: movie_test_df")
print(movie_test_df)
#
# Build up of movie_train_df. This will contain train data set. The starter movie_train_df, is just a copy of the given movie_ratings_df.
# We'll populate this with 75% of the original data in movie_ratings_df.
#
movie_train_df = movie_ratings_df.copy()
print()
print("Starter data set: movie_train_df")
print(movie_train_df)
#
# Now, we'll build up movie_train_df and movie_test_df, with actual values from movie_ratings_df. Since our goal is to reduce ON-values
# of a program, we built up raw_average_train (average of the train data set), raw_count_train (number of actual numeric ratings in train)
# and raw_count_test (number of actual numeric ratings in test) in the same loop.
#
# Since memory is expensive, we did not expend a separate variable, but added the movie ratings to raw_average_train.
#
raw_average_train = 0
raw_count_train = 0
raw_count_test = 0
#
for row in range(0, rows):
    for col in range(0, columns):
        if movie_ratings_df.iloc[row, col] == "?":
            if movie_test_df.iloc[row, col]:
                movie_test_df.iloc[row, col] = movie_ratings_df.iloc[row, col]
        else:
            if movie_test_df.iloc[row, col]:
                movie_test_df.iloc[row, col] = movie_ratings_df.iloc[row, col]
                movie_train_df.iloc[row, col] = "-"
                raw_count_test = raw_count_test + 1
            else:
                raw_average_train = raw_average_train + float(movie_ratings_df.iloc[row, col])
                raw_count_train = raw_count_train + 1
#
print()
print("Populated data set: movie_test_df")
print(movie_test_df)
#
print()
print("Populated data set: movie_train_df")
print(movie_train_df)
#
# Computing the raw_average_train.
#
try:
    raw_average_train = raw_average_train / raw_count_train
except ZeroDivisionError as err:
    sys.exit("movie_ratings.csv doesn't have any numeric ratings, exiting program....")
#
print()
print("raw_average_train = ", round(raw_average_train, 2))
print("raw_count_train   = ", round(raw_count_train, 2))
print("raw_count_test    = ", raw_count_test)
#
# Computation of RMSE for movie_train_df and movie_test_df:
# We'll use raw_average_train, raw_count_train and raw_count_test for the below computations.
#
# As stated before, we like to reduce the ON-values of a program, so we'll compute the user and movie biases in the same loop.
# In order to contain the biases and some related computational values, we created two data frames: user_bias_df and movie_bias_df.
#
user_bias_df = pd.DataFrame(np.zeros((rows, 2)), columns = ["User bias", "Count"], index = list(movie_ratings_df.index.values))
movie_bias_df = pd.DataFrame(np.zeros((2, columns)), columns = list(movie_ratings_df.columns.values), index = ["Movie rating", "Count"])
#
rmse_train = 0
rmse_test = 0
#
for row in range(0, rows):
    for col in range(0, columns):
        if movie_train_df.iloc[row, col] != "?" and movie_train_df.iloc[row, col] != "-":
            rmse_train = rmse_train + (float(movie_train_df.iloc[row, col]) - raw_average_train) ** 2
            user_bias_df.iloc[row, 0] = user_bias_df.iloc[row, 0] + float(movie_ratings_df.iloc[row, col])
            user_bias_df.iloc[row, 1] = user_bias_df.iloc[row, 1] + 1
            movie_bias_df.iloc[0, col] = movie_bias_df.iloc[0, col] + float(movie_ratings_df.iloc[row, col])
            movie_bias_df.iloc[1, col] = movie_bias_df.iloc[1, col] + 1
        if movie_test_df.iloc[row, col] and movie_test_df.iloc[row, col] != "?":
            rmse_test = rmse_test + (float(movie_test_df.iloc[row, col]) - raw_average_train) ** 2
#
# Final computation of RMSE
#
rmse_train = rmse_train / raw_count_train
rmse_train = np.math.sqrt(rmse_train)
#
rmse_test = rmse_test / raw_count_test
rmse_test = np.math.sqrt(rmse_test)
#
print()
print("rmse_train = ", round(rmse_train, 2))
print("rmse_test = ", round(rmse_test, 2))
#
# Computations of user and movie biases
#
user_bias_df["User bias"] = user_bias_df["User bias"] / user_bias_df["Count"] - raw_average_train
movie_bias_df.loc["Movie rating"] = movie_bias_df.loc["Movie rating"] / movie_bias_df.loc["Count"] - raw_average_train
#
print()
print("Populated data set: user_bias_df")
print(round(user_bias_df["User bias"], 2))
#
print()
print("Populated data set: movie_bias_df")
print(round(movie_bias_df.loc["Movie rating"], 2))
#
# An inspection of the above prints of user_bias_df and movie_bias_df, in sorted manner, clearly tells the harshest user
# to the most lenient user, and worst rated to best movies.
#
# Creating Baseline Predictors. Initially we created an empty data frame, called baseline_predictors_df, populated with
# raw_average_train in every cell. In baseline_predictors_df, we'll add the raw_average_train (placed in every cell) with
# user bias and movie bias.
#
baseline_predictors_df = pd.DataFrame(np.full((rows, columns), raw_average_train),
                  columns = list(movie_ratings_df.columns.values),
                  index = list(movie_ratings_df.index.values))
#
for row in range(0, rows):
    for col in range(0, columns):
        baseline_predictors_df.iloc[row, col] = baseline_predictors_df.iloc[row, col] + user_bias_df.iloc[row, 0] + movie_bias_df.iloc[0, col]
        if baseline_predictors_df.iloc[row, col] > 5:
            baseline_predictors_df.iloc[row, col] = 5
        elif baseline_predictors_df.iloc[row, col] < 1:
            baseline_predictors_df.iloc[row, col] = 1
#
print()
print("baseline_predictors_df")
print(round(baseline_predictors_df, 2))
#
# Computation of RMSE with respect to Baseline Predictors, for movie_train_df and movie_test_df:
#
baseline_rmse_train = 0
baseline_rmse_train_count = 0
#
baseline_rmse_test = 0
baseline_rmse_test_count = 0
#
for row in range(0, rows):
    for col in range(0, columns):
        if movie_train_df.iloc[row, col] != "?":
                if movie_train_df.iloc[row, col] != "-":
                    baseline_rmse_train = baseline_rmse_train + ( float(movie_train_df.iloc[row, col]) - float(baseline_predictors_df.iloc[row, col]) ) ** 2
                    baseline_rmse_train_count = baseline_rmse_train_count + 1
                else:
                    baseline_rmse_test = baseline_rmse_test + ( float(movie_test_df.iloc[row, col]) - float(baseline_predictors_df.iloc[row, col]) ) ** 2
                    baseline_rmse_test_count = baseline_rmse_test_count + 1
#
baseline_rmse_train = baseline_rmse_train / baseline_rmse_train_count
baseline_rmse_train = np.math.sqrt(baseline_rmse_train)
#
baseline_rmse_test = baseline_rmse_test / baseline_rmse_test_count
baseline_rmse_test = np.math.sqrt(baseline_rmse_test)
#
print()
print("baseline_rmse_train = ", round(baseline_rmse_train, 2))
print("baseline_rmse_test = ", round(baseline_rmse_test, 2))
#
# So, the percentage difference between rmse_train and baseline_rmse_train, and rmse_test and baseline_rmse_test are:
# (rmse_train - baseline_rmse_train) / rmse_train and (rmse_test - baseline_rmse_train) / rmse_test respectively.
# We'll compute the differentials below:
#
train_differential = ( (rmse_train - baseline_rmse_train) / rmse_train ) * 100
rmse_differential = ( (rmse_test - baseline_rmse_train) / rmse_test ) * 100
#
print()
print("train_differential = ", round(train_differential, 2), "%")
print("test_differential = ", round(rmse_differential, 2), "%")
#
# Summary:
# 1) We read the movies data set and split them cells on 25% (test) and 75% (train) basis.
# 2) Computed raw_average_train i.e. "Raw Average".
# 3) Computed RMSE, for train and test data sets. Used Raw Average, for the computation.
# 4) Computed User and Movie biases.
# 5) Computed the Baseline Predictor matrix.
# 6) Computed RMSE with respect to Baseline Predictor, for train and test data sets.
# 7) Checked the improvement of the RMSE.
#
# We did not split the movie data set, using Python's own splitting function, because it splits the data frame by entire
# rows or columns, not cells. Based on the instruction video, we selected arbitrary cells.